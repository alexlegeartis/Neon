{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21375182  0.03528199 -0.42474652  0.04549682 -0.87783015]\n",
      "[-0.71021228  0.66699818 -0.22519313]\n",
      "2.585417084007863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "W = np.random.randn(5, 3)  # example matrix\n",
    "U, S, Vt = np.linalg.svd(W, full_matrices=False)\n",
    "\n",
    "u = U[:, 0]      # Left singular vector\n",
    "v = Vt[0, :]     # Right singular vector (note: Vt = V.T)\n",
    "print(u)\n",
    "print(v)\n",
    "print(S[0])  # Singular value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21375095  0.03528089 -0.42474556  0.04549703 -0.87783086]\n",
      "[-0.71021302  0.66699792 -0.22519157]\n",
      "2.585417084007349\n"
     ]
    }
   ],
   "source": [
    "def top_singular_vectors(W, num_iter=100):\n",
    "    v = np.random.randn(W.shape[1])\n",
    "    v /= np.linalg.norm(v)\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        u = W @ v\n",
    "        u /= np.linalg.norm(u)\n",
    "        v = W.T @ u\n",
    "        v /= np.linalg.norm(v)\n",
    "    \n",
    "    return u, v\n",
    "\n",
    "u, v = top_singular_vectors(W)\n",
    "print(u)\n",
    "print(v)\n",
    "print(u.T @ W @ v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def u1s1v1t(W, num_iter=30):\n",
    "    \"\"\"Power iteration using PyTorch operations\"\"\"\n",
    "    v = np.random.randn(W.shape[1])\n",
    "    v /= np.linalg.norm(v)\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        u = W @ v\n",
    "        u /= np.linalg.norm(u)\n",
    "        v = W.T @ u\n",
    "        v /= np.linalg.norm(v)\n",
    "    sigma1 = (u.T @ W @ v)\n",
    "    u = u.reshape(-1, 1)         # shape: (5, 1)\n",
    "    v = v.reshape(-1, 1)         # shape: (3, 1)\n",
    "    return sigma1 * u @ v.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupyx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m svds \u001b[38;5;28;01mas\u001b[39;00m cupyx_svds\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mu1s1v1t_svds\u001b[39m(W, num_iter=\u001b[32m30\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from cupyx.scipy.sparse.linalg import svds as cupyx_svds\n",
    "\n",
    "def u1s1v1t_svds(W, num_iter=30):\n",
    "    assert (W.shape[0] > 3 and W.shape[1] > 3), \"dimentions of W must be grater than 3\"\n",
    "    U, S, Vt = cupyx_svds(W,k=1,maxiter=num_iter,which='LM')\n",
    "\n",
    "    sigma1 = S[0]  # Largest singular value\n",
    "    u = U[:, 0].reshape(-1, 1)  # Reshape to column vector\n",
    "    v = Vt[0, :].reshape(-1, 1) # Reshape to column vector\n",
    "    \n",
    "    return sigma1 * (u @ v.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cupyx.scipy.sparse.linalg import svds as cupyx_svds\n",
    "\n",
    "def k_sv_svds_approximation(W, k, tau, num_iter=30):\n",
    "    \"\"\"SVD approximation using the top k singular values and corresponding vectors.\"\"\"\n",
    "    \n",
    "    assert (W.shape[0] > 3 and W.shape[1] > 3), \"Dimensions of W must be greater than 3\"\n",
    "    \n",
    "    U, S, Vt = cupyx_svds(W, k=k, maxiter=num_iter, which='LM')\n",
    "    S_thresholded = cp.maximum(S - tau, 0)\n",
    "    approx = U @ cp.diag(S_thresholded) @ Vt\n",
    "    \n",
    "    return approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cupyx.scipy.sparse.linalg import svds as cupyx_svds\n",
    "import torch\n",
    "import time\n",
    "import torch.utils.dlpack as thd\n",
    "\n",
    "\n",
    "def k_sv_rsvd_approximation(W, k, tau, num_iter=30):\n",
    "    \"\"\"SVD approximation using the top k singular values/vectors via randomized SVD.\"\"\"\n",
    "    \n",
    "    U, S, V = torch.pca_lowrank(W, q=k, niter=num_iter, center=False)\n",
    "    S_thresholded = torch.clamp(S - tau, min=0) \n",
    "    approx = U @ torch.diag(S_thresholded) @ V.T  \n",
    "\n",
    "    return approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from petsc4py import PETSc\n",
    "# from slepc4py import SLEPc\n",
    "\n",
    "# def u1s1v1t_slepc(W_numpy, num_iter=30):\n",
    "#     \"\"\"Compute rank-1 approximation using SLEPc's Lanczos SVD\"\"\"\n",
    "#     m, n = W_numpy.shape\n",
    "    \n",
    "#     # Convert to PETSc matrix (sparse-friendly)\n",
    "#     A = PETSc.Mat().createDense((m, n), array=W_numpy)\n",
    "#     A.assemble()\n",
    "\n",
    "#     # Create and configure SVD solver\n",
    "#     svd = SLEPc.SVD().create()\n",
    "#     svd.setOperator(A)\n",
    "#     svd.setType(SLEPc.SVD.Type.LANCZOS)  # Directly use Lanczos SVD method\n",
    "#     svd.setDimensions(1)                 # Request 1 singular value\n",
    "#     svd.setTolerances(max_it=num_iter)    # Set iteration limit\n",
    "#     svd.setWhichSingularTriplets(SLEPc.SVD.Which.LARGEST)\n",
    "    \n",
    "#     # Solve SVD\n",
    "#     svd.solve()\n",
    "\n",
    "#     # Check convergence\n",
    "#     if svd.getConverged() < 1:\n",
    "#         raise RuntimeError(\"SVD failed to converge\")\n",
    "\n",
    "#     # Extract results\n",
    "#     sigma = svd.getSingularValue(0)\n",
    "#     u, v = A.getVecLeft(), A.getVecRight()\n",
    "#     svd.getSingularTriplet(0, u, v)\n",
    "\n",
    "#     return sigma * np.outer(u.getArray(), v.getArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error of power iterations:\n",
      " 0.0001565592476726586\n",
      "relative error of svds:\n",
      " 0.0008517115739312306\n",
      "time for svds: 0.19017505645751953\n",
      "time for power iterations: 0.9094109535217285\n"
     ]
    }
   ],
   "source": [
    "# test_matr = cp.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "import time\n",
    "np.random.seed(42)\n",
    "W_numpy = np.random.randn(1000, 1000)\n",
    "W_gpu = cp.asarray(W_numpy)\n",
    "\n",
    "start = time.time()\n",
    "result_gpu = u1s1v1t_svds(W_gpu, num_iter=3)\n",
    "time_svds = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "result_cpu = u1s1v1t(W_numpy, num_iter=1000)\n",
    "time_power_iter = time.time() - start\n",
    "\n",
    "# result_slepc = u1s1v1t_slepc(W_numpy, num_iter=3)\n",
    "\n",
    "U, S, Vt = np.linalg.svd(W_numpy)\n",
    "result_precise = S[0] * (U[:, 0].reshape(-1, 1) @ Vt[0, :].reshape(-1, 1).T)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': '{:.2f}'.format})\n",
    "# print(\"svds_gpu:\\n\",result_gpu, \"\\n\\n\", \"power_iters_cpu:\\n\",result_cpu, \"\\n\\n\", \"precise:\\n\",result_precise)\n",
    "print(\"relative error of power iterations:\\n\", np.linalg.norm(result_cpu-result_precise)/np.linalg.norm(result_precise))\n",
    "print(\"relative error of svds:\\n\", np.linalg.norm(cp.asnumpy(result_gpu)-result_precise)/np.linalg.norm(result_precise))\n",
    "# print(\"relative error of slepc:\\n\",            np.linalg.norm(result_slepc-result_precise)/np.linalg.norm(result_precise))\n",
    "print(f'time for svds: {time_svds}')\n",
    "print(f'time for power iterations: {time_power_iter}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison SVDS VS RSVD for approximation with k singular vectors\n",
    "\n",
    "# initialization of test\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "N=5000\n",
    "k=100\n",
    "tau = 0.01\n",
    "\n",
    "np.random.seed(42)\n",
    "W_numpy = np.random.randn(N, N)\n",
    "W_gpu = cp.asarray(W_numpy)\n",
    "W_torch = thd.from_dlpack(W_gpu.toDlpack()) \n",
    "\n",
    "start = time.time()\n",
    "U, S, Vt = np.linalg.svd(W_numpy)\n",
    "result_precise =  U[:,:k] @ np.diag(S[:k]) @ Vt[:k,:]\n",
    "time_precise = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# test approximations separately from precise solution, so to not waste time\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m start = \u001b[43mtime\u001b[49m.time()\n\u001b[32m      3\u001b[39m result_gpu = k_sv_svds_approximation(W_gpu, k=k,tau= tau, num_iter=\u001b[32m700\u001b[39m)\n\u001b[32m      4\u001b[39m time_svds = time.time() - start\n",
      "\u001b[31mNameError\u001b[39m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# test approximations separately from precise solution, so to not waste time\n",
    "start = time.time()\n",
    "result_gpu = k_sv_svds_approximation(W_gpu, k=k,tau= tau, num_iter=700)\n",
    "time_svds = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "result_rsvd = k_sv_rsvd_approximation(W_torch, k=k, tau = tau,num_iter=50)\n",
    "time_rsvd = time.time() - start\n",
    "result_rsvd = cp.from_dlpack(thd.to_dlpack(result_rsvd))\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': '{:.2f}'.format})\n",
    "print(\"relative error of svds:\\n\", np.linalg.norm(cp.asnumpy(result_gpu)-result_precise)/np.linalg.norm(result_precise))\n",
    "print(\"relative error of rsvd:\\n\", np.linalg.norm(cp.asnumpy(result_rsvd)-result_precise)/np.linalg.norm(result_precise))\n",
    "\n",
    "print(f'time for svds: {time_svds}')\n",
    "print(f'time for rsvd: {time_rsvd}')\n",
    "\n",
    "print(f'time for precise: {time_precise}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
